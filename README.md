# Vision Transformer (ViT) in PyTorch

This project contains a clean, modular implementation of a Vision Transformer for image classification (e.g., CIFAR-10).

## ğŸ“ Project Structure
```
vision_transformer_project/
â”œâ”€â”€ vit_example.py        # Main script for training/evaluation
â”œâ”€â”€ config.py             # Configuration dictionary
â”œâ”€â”€ requirements.txt      # Project dependencies
â”œâ”€â”€ README.md             # Project overview and instructions
â”œâ”€â”€ models/vit.py         # ViT model definition
â”œâ”€â”€ data/dataset.py       # Data loading and transforms
â”œâ”€â”€ train/trainer.py      # Training loop logic
â”œâ”€â”€ train/evaluate.py     # Evaluation logic
â”œâ”€â”€ utils/helpers.py      # Utilities (checkpointing, etc.)
â”œâ”€â”€ utils/visualize.py    # Attention map visualization
â””â”€â”€ checkpoints/          # Saved model weights
```

## ğŸš€ Getting Started

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train the Model
```bash
python vit_example.py --mode train --epochs 20 --lr 1e-4
```

### 3. Evaluate the Model
```bash
python vit_example.py --mode eval --checkpoint checkpoints/vit_epoch10.pt
```

### 4. Visualize Attention
```python
from models.vit import VisionTransformer
from utils.visualize import visualize_attention
import torch

# Load model and image
model = VisionTransformer(**cfg['model_params']).to(cfg['device'])
model.load_state_dict(torch.load('checkpoints/vit_epoch10.pt', map_location=cfg['device']))
# Assume `image_tensor` is a torch.Tensor of shape [3, H, W]
visualize_attention(model, image_tensor)
```

## ğŸ“š Features
- From-scratch ViT implementation
- Configurable via `config.py`
- CLI with `argparse`
- Checkpointing and logging utilities
- Attention visualization
- MPS/GPU/CPU support

## ğŸ› ï¸ To Do
- Add custom dataset support
- Data augmentation pipelines
- Pretrained weights loading
- Experiment logging (TensorBoard, W&B)